{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIND 数据集预处理 (基于新划分)\n",
    "\n",
    "## 说明\n",
    "本脚本基于重新划分的数据 (7:2:1) 生成训练样本,输出文件名保持不变以兼容现有配置。\n",
    "\n",
    "**输出文件**:\n",
    "- `./data/processed/mind_train.json` (覆盖)\n",
    "- `./data/processed/mind_val.json` (覆盖)\n",
    "- `./data/processed/mind_test.json` (覆盖)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本数量限制配置:\n",
      "  训练集: 120000\n",
      "  验证集: 20000\n",
      "  测试集: 10000\n",
      "  随机种子: 42\n"
     ]
    }
   ],
   "source": [
    "# ===== 样本数量限制配置 =====\n",
    "MAX_TRAIN_SAMPLES = 120000  # 训练集最大样本数 (None=不限制, 例如: 1000000)\n",
    "MAX_VAL_SAMPLES = 20000    # 验证集最大样本数 (None=不限制, 例如: 100000)\n",
    "MAX_TEST_SAMPLES = 10000   # 测试集最大样本数 (None=不限制, 例如: 50000)\n",
    "RANDOM_SEED = 42          # 随机种子 (保证可复现性)\n",
    "# ==========================\n",
    "\n",
    "print(\"样本数量限制配置:\")\n",
    "print(f\"  训练集: {MAX_TRAIN_SAMPLES if MAX_TRAIN_SAMPLES else '不限制'}\")\n",
    "print(f\"  验证集: {MAX_VAL_SAMPLES if MAX_VAL_SAMPLES else '不限制'}\")\n",
    "print(f\"  测试集: {MAX_TEST_SAMPLES if MAX_TEST_SAMPLES else '不限制'}\")\n",
    "print(f\"  随机种子: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一步: 构建统一的新闻字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在读取合并后的 news.tsv...\n",
      "新闻字典大小: 104,151 条\n",
      "\n",
      "示例:\n",
      "  N88753: The Brands Queen Elizabeth, Prince Charles, and Prince Philip Swear By\n",
      "  N45436: Walmart Slashes Prices on Last-Generation iPads\n",
      "  N23144: 50 Worst Habits For Belly Fat\n"
     ]
    }
   ],
   "source": [
    "# 使用合并后的 news.tsv 构建统一字典\n",
    "print(\"正在读取合并后的 news.tsv...\")\n",
    "news_merged = pd.read_csv('./data/MIND/merged/news.tsv', sep='\\t', header=None)\n",
    "news_merged.columns = [\"ID\", \"类别\", \"子类别\", \"标题\", \"摘要\", \"链接\", \"标题实体\", \"摘要实体\"]\n",
    "\n",
    "# 构建新闻ID到标题的映射\n",
    "news_dict = dict(zip(news_merged[\"ID\"], news_merged[\"标题\"]))\n",
    "\n",
    "print(f\"新闻字典大小: {len(news_dict):,} 条\")\n",
    "print(f\"\\n示例:\")\n",
    "for i, (news_id, title) in enumerate(list(news_dict.items())[:3]):\n",
    "    print(f\"  {news_id}: {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二步: 读取划分后的 behaviors 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在读取 behaviors 数据...\n",
      "训练集: 1,823,973 条\n",
      "验证集: 523,103 条\n",
      "测试集: 262,143 条\n"
     ]
    }
   ],
   "source": [
    "# 读取三个数据集的 behaviors.tsv\n",
    "print(\"正在读取 behaviors 数据...\")\n",
    "behaviors_train = pd.read_csv('./data/MIND/new_split/train/behaviors.tsv', sep='\\t', header=None)\n",
    "behaviors_val = pd.read_csv('./data/MIND/new_split/val/behaviors.tsv', sep='\\t', header=None)\n",
    "behaviors_test = pd.read_csv('./data/MIND/new_split/test/behaviors.tsv', sep='\\t', header=None)\n",
    "\n",
    "# 处理 NaN 值\n",
    "behaviors_train = behaviors_train.fillna('')\n",
    "behaviors_val = behaviors_val.fillna('')\n",
    "behaviors_test = behaviors_test.fillna('')\n",
    "\n",
    "# 设置列名\n",
    "behaviors_train.columns = [\"曝光ID\", \"用户ID\", \"曝光时间\", \"曝光前的新闻点击历史\", \"曝光明细 (1表示点击；0表示非点击)\"]\n",
    "behaviors_val.columns = [\"曝光ID\", \"用户ID\", \"曝光时间\", \"曝光前的新闻点击历史\", \"曝光明细 (1表示点击；0表示非点击)\"]\n",
    "behaviors_test.columns = [\"曝光ID\", \"用户ID\", \"曝光时间\", \"曝光前的新闻点击历史\", \"曝光明细 (1表示点击；0表示非点击)\"]\n",
    "\n",
    "print(f\"训练集: {len(behaviors_train):,} 条\")\n",
    "print(f\"验证集: {len(behaviors_val):,} 条\")\n",
    "print(f\"测试集: {len(behaviors_test):,} 条\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三步: 构建样本的通用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(samples, max_samples, dataset_name, random_seed=42):\n",
    "    \"\"\"\n",
    "    随机采样限制样本数量\n",
    "\n",
    "    Args:\n",
    "        samples: 原始样本列表\n",
    "        max_samples: 最大样本数 (None 表示不限制)\n",
    "        dataset_name: 数据集名称 (用于日志)\n",
    "        random_seed: 随机种子\n",
    "\n",
    "    Returns:\n",
    "        sampled_samples: 采样后的样本列表\n",
    "    \"\"\"\n",
    "    if max_samples is None or len(samples) <= max_samples:\n",
    "        print(f\"{dataset_name}: 保留全部 {len(samples):,} 个样本\")\n",
    "        return samples\n",
    "\n",
    "    import random\n",
    "    random.seed(random_seed)\n",
    "    sampled = random.sample(samples, max_samples)\n",
    "    print(f\"{dataset_name}: 从 {len(samples):,} 个样本中随机采样 {max_samples:,} 个 ({max_samples/len(samples)*100:.1f}%)\")\n",
    "    return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指令模板\n",
    "instruction = \"You are a news recommendation expert. Given the news click history (if the user has no news click history, indicate it as no click history) of the user and the news they like and dislike to watch, please decide whether the user likes to watch the target news by outputting \\\"Yes.\\\" or \\\"No.\\\"\"\n",
    "\n",
    "def build_samples(behaviors_df, dataset_name):\n",
    "    \"\"\"\n",
    "    从 behaviors DataFrame 构建训练样本\n",
    "    \n",
    "    Args:\n",
    "        behaviors_df: behaviors DataFrame\n",
    "        dataset_name: 数据集名称 (用于日志)\n",
    "    \n",
    "    Returns:\n",
    "        samples: 样本列表\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    error_count = 0\n",
    "    \n",
    "    print(f\"\\n正在处理 {dataset_name} 数据集...\")\n",
    "    \n",
    "    for idx, row in tqdm(behaviors_df.iterrows(), total=len(behaviors_df), desc=f\"处理 {dataset_name}\"):\n",
    "        try:\n",
    "            sample_input = \"\"\n",
    "            \n",
    "            # 处理点击历史\n",
    "            click_news_histories = []\n",
    "            if len(row[\"曝光前的新闻点击历史\"]) > 0:\n",
    "                click_news = row[\"曝光前的新闻点击历史\"].split(\" \")\n",
    "                \n",
    "                # 如果大于3个,则选最后3个\n",
    "                if len(click_news) >= 3:\n",
    "                    click_news = click_news[-3:]\n",
    "                \n",
    "                for each_news in click_news:\n",
    "                    if each_news in news_dict:\n",
    "                        click_news_histories.append('\"' + news_dict[each_news] + '\"')\n",
    "            else:\n",
    "                click_news_histories.append('the user do not has click history.')\n",
    "            \n",
    "            # 处理曝光明细\n",
    "            impressions = row[\"曝光明细 (1表示点击；0表示非点击)\"].split(\" \")\n",
    "            likes = []\n",
    "            dislikes = []\n",
    "            \n",
    "            # 前面的新闻作为训练数据,最后一个新闻作为预测目标\n",
    "            for impression in impressions[:-1]:\n",
    "                news_id, click = impression.split(\"-\")\n",
    "                if news_id in news_dict:\n",
    "                    news_title = news_dict[news_id]\n",
    "                    if int(click) == 1:\n",
    "                        likes.append('\"' + news_title + '\"')\n",
    "                    else:\n",
    "                        dislikes.append('\"' + news_title + '\"')\n",
    "            \n",
    "            # 构建输入\n",
    "            sample_input = \"User click histories: \" + \", \".join(click_news_histories) + \"\\n\"\n",
    "            sample_input += \"User likes: \" + ', '.join(likes) + \"\\n\" + \"User dislikes: \" + ', '.join(dislikes)\n",
    "            \n",
    "            # 目标新闻\n",
    "            news_id, click = impressions[-1].split(\"-\")\n",
    "            if news_id not in news_dict:\n",
    "                continue\n",
    "                \n",
    "            output = \"Yes.\" if int(click) == 1 else \"No.\"\n",
    "            sample_input = sample_input + \"\\n\" + \"Whether the user will like the target news \" + '\"' + news_dict[news_id] + '\"?'\n",
    "            \n",
    "            sample = {\n",
    "                \"instruction\": instruction,\n",
    "                \"input\": sample_input,\n",
    "                \"output\": output,\n",
    "                \"用户ID\": row[\"用户ID\"]\n",
    "            }\n",
    "            samples.append(sample)\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_count += 1\n",
    "            if error_count <= 5:  # 只打印前5个错误\n",
    "                print(f\"\\n解析曝光ID {row['曝光ID']} 时出错: {e}\")\n",
    "    \n",
    "    print(f\"\\n{dataset_name} 处理完成: {len(samples):,} 个样本, {error_count} 个错误\")\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第四步: 生成训练集样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "正在处理 训练集 数据集...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理 训练集: 100%|██████████| 1823973/1823973 [02:36<00:00, 11681.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "训练集 处理完成: 1,823,973 个样本, 0 个错误\n"
     ]
    }
   ],
   "source": [
    "samples_train = build_samples(behaviors_train, \"训练集\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "训练集样本示例:\n",
      "{\n",
      "  \"instruction\": \"You are a news recommendation expert. Given the news click history (if the user has no news click history, indicate it as no click history) of the user and the news they like and dislike to watch, please decide whether the user likes to watch the target news by outputting \\\"Yes.\\\" or \\\"No.\\\"\",\n",
      "  \"input\": \"User click histories: \\\"A couple's attempt to re-create a picture-perfect engagement photo with a bottle of Champagne totally backfired, but the result is going viral\\\", \\\"Which Royal Wore It Best?\\\", \\\"Meghan King Edmonds and Jim Edmonds Split After 5 Years of Marriage\\\"\\nUser likes: \\\"John Travolta Shares Rare Photo of Son Ben, 8, in Plane Cockpit: He's 'Taking My Place!'\\\", \\\"Rep. Ilhan Omar is accused of 'dog whistle' anti-Semitism after she posts tweet implying billionaire businessman Leon Cooperman is only supporting Michael Bloomberg's presidential run because he is Jewish\\\", \\\"Missing California hiker found dead at top of glacier just weeks before baby was due\\\", \\\"Broadway Actress Laurel Griggs Dies at Age 13\\\"\\nUser dislikes: \\\"Sarah Hyland documents painful tattoo removal\\\", \\\"Roommate, her boyfriend charged in death of missing Atlanta student\\\", \\\"This little Montana town is full of Power Wagons and Mustangs\\\", \\\"Christmas tree decorating ideas for every style and budget\\\", \\\"100 vintage baby names coming back into style\\\", \\\"Stop! Read This Guide Before You Buy an Air Fryer.\\\", \\\"LSU, Ohio State, and Clemson control path to College Football Playoff, but who else does too?\\\", \\\"Meghan Markle and Prince Harry Reunite with Kate Middleton and Prince William for Remembrance Service\\\", \\\"Industries Where Your Job Is Most Likely To Get Outsourced\\\", \\\"Distressing photos show glaciers that are disappearing or on the brink of collapse around the world\\\", \\\"2020 Democratic Voters Divided Down Demographic Lines\\\", \\\"Week in celebrity photos for Nov. 4-8, 2019\\\", \\\"Judge includes law student's toddler during sweet swearing-in ceremony\\\", \\\"A Texas woman was legally declared dead while still alive\\\"\\nWhether the user will like the target news \\\"An investor's guide to space, Wall Street's next trillion-dollar industry\\\"?\",\n",
      "  \"output\": \"No.\",\n",
      "  \"用户ID\": \"U87243\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 查看样本示例\n",
    "print(\"\\n训练集样本示例:\")\n",
    "print(json.dumps(samples_train[0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第五步: 生成验证集样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "正在处理 验证集 数据集...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理 验证集: 100%|██████████| 523103/523103 [00:43<00:00, 12062.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "验证集 处理完成: 523,103 个样本, 0 个错误\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "samples_val = build_samples(behaviors_val, \"验证集\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第六步: 生成测试集样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "正在处理 测试集 数据集...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理 测试集: 100%|██████████| 262143/262143 [00:21<00:00, 12330.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "测试集 处理完成: 262,143 个样本, 0 个错误\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "samples_test = build_samples(behaviors_test, \"测试集\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第七步: 保存样本 (覆盖原文件)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "应用样本数量限制\n",
      "============================================================\n",
      "训练集: 从 1,823,973 个样本中随机采样 120,000 个 (6.6%)\n",
      "验证集: 从 523,103 个样本中随机采样 20,000 个 (3.8%)\n",
      "测试集: 从 262,143 个样本中随机采样 10,000 个 (3.8%)\n",
      "\n",
      "采样后的数据集大小:\n",
      "  - 训练集: 120,000 样本\n",
      "  - 验证集: 20,000 样本\n",
      "  - 测试集: 10,000 样本\n"
     ]
    }
   ],
   "source": [
    "# 应用样本数量限制\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"应用样本数量限制\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "samples_train = sample_data(samples_train, MAX_TRAIN_SAMPLES, \"训练集\", RANDOM_SEED)\n",
    "samples_val = sample_data(samples_val, MAX_VAL_SAMPLES, \"验证集\", RANDOM_SEED)\n",
    "samples_test = sample_data(samples_test, MAX_TEST_SAMPLES, \"测试集\", RANDOM_SEED)\n",
    "\n",
    "print(\"\\n采样后的数据集大小:\")\n",
    "print(f\"  - 训练集: {len(samples_train):,} 样本\")\n",
    "print(f\"  - 验证集: {len(samples_val):,} 样本\")\n",
    "print(f\"  - 测试集: {len(samples_test):,} 样本\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "正在保存样本文件...\n",
      "总样本数: 150,000\n",
      "  - 训练集: 120,000\n",
      "  - 验证集: 20,000\n",
      "  - 测试集: 10,000\n",
      "\n",
      "✓ 已保存: ./data/processed/mind_train.json\n",
      "✓ 已保存: ./data/processed/mind_val.json\n",
      "✓ 已保存: ./data/processed/mind_test.json\n"
     ]
    }
   ],
   "source": [
    "# 确保输出目录存在\n",
    "os.makedirs('./data/processed', exist_ok=True)\n",
    "\n",
    "print(f\"\\n正在保存样本文件...\")\n",
    "print(f\"总样本数: {len(samples_train) + len(samples_val) + len(samples_test):,}\")\n",
    "print(f\"  - 训练集: {len(samples_train):,}\")\n",
    "print(f\"  - 验证集: {len(samples_val):,}\")\n",
    "print(f\"  - 测试集: {len(samples_test):,}\")\n",
    "\n",
    "# 保存训练集\n",
    "with open(\"./data/processed/mind_train.json\", \"w\", encoding='utf-8') as save_file:\n",
    "    json.dump(samples_train, save_file, indent=4, ensure_ascii=False)\n",
    "print(\"\\n✓ 已保存: ./data/processed/mind_train.json\")\n",
    "\n",
    "# 保存验证集\n",
    "with open(\"./data/processed/mind_val.json\", \"w\", encoding='utf-8') as save_file:\n",
    "    json.dump(samples_val, save_file, indent=4, ensure_ascii=False)\n",
    "print(\"✓ 已保存: ./data/processed/mind_val.json\")\n",
    "\n",
    "# 保存测试集\n",
    "with open(\"./data/processed/mind_test.json\", \"w\", encoding='utf-8') as save_file:\n",
    "    json.dump(samples_test, save_file, indent=4, ensure_ascii=False)\n",
    "print(\"✓ 已保存: ./data/processed/mind_test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第八步: 数据统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "训练集 标签分布:\n",
      "  Yes: 12,889 (10.7%)\n",
      "  No: 107,111 (89.3%)\n",
      "\n",
      "验证集 标签分布:\n",
      "  Yes: 2,152 (10.8%)\n",
      "  No: 17,848 (89.2%)\n",
      "\n",
      "测试集 标签分布:\n",
      "  Yes: 1,076 (10.8%)\n",
      "  No: 8,924 (89.2%)\n"
     ]
    }
   ],
   "source": [
    "# 统计 Yes/No 分布\n",
    "def count_labels(samples, dataset_name):\n",
    "    yes_count = sum(1 for s in samples if s['output'] == 'Yes.')\n",
    "    no_count = sum(1 for s in samples if s['output'] == 'No.')\n",
    "    print(f\"\\n{dataset_name} 标签分布:\")\n",
    "    print(f\"  Yes: {yes_count:,} ({yes_count/len(samples)*100:.1f}%)\")\n",
    "    print(f\"  No: {no_count:,} ({no_count/len(samples)*100:.1f}%)\")\n",
    "\n",
    "count_labels(samples_train, \"训练集\")\n",
    "count_labels(samples_val, \"验证集\")\n",
    "count_labels(samples_test, \"测试集\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "数据预处理完成!\n",
      "============================================================\n",
      "\n",
      "下一步: 使用以下命令开始训练\n",
      "llamafactory-cli train new_train.yaml\n",
      "\n",
      "注意: 配置文件自动加载新的 mind_train.json\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"数据预处理完成!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n下一步: 使用以下命令开始训练\")\n",
    "print(\"llamafactory-cli train new_train.yaml\")\n",
    "print(\"\\n注意: 配置文件自动加载新的 mind_train.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
